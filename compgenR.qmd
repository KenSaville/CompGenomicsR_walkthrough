---
title: "CompGenR"
format: html
editor: visual
---

## Quarto

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>.

## Running Code

When you click the **Render** button a document will be generated that includes both content and the output of embedded code. You can embed code like this:

```{r}
1 + 1
```

You can add options to executable code like this

```{r}
#| echo: false
2 * 2
```

The `echo: false` option disables the printing of code (only output is displayed).

# Computational Genomics with R

This is my walkthrough of the book computational genomics with R by Altuna Alkalin, which can be found [here](https://compgenomr.github.io/book/).

### Compute resources

I'm starting out with the initial allocation from Posit.

1GB Ram, 1 CPU

We'll see if I need to / can bump that up if needed.

### Installations

First install all of the packages. Code copied from the preface of the book. Let's hope it works. That's a lot of packages.

```{r eval=FALSE, include=FALSE}

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install(c('qvalue','plot3D','ggplot2','pheatmap','cowplot',
                      'cluster', 'NbClust', 'fastICA', 'NMF','matrixStats',
                      'Rtsne', 'mosaic', 'knitr', 'genomation',
                      'ggbio', 'Gviz', 'DESeq2', 'RUVSeq',
                      'gProfileR', 'ggfortify', 'corrplot',
                      'gage', 'EDASeq', 'citr', 'formatR',
                      'svglite', 'Rqc', 'ShortRead', 'QuasR',
                      'methylKit','FactoMineR', 'iClusterPlus',
                      'enrichR','caret','xgboost','glmnet',
                      'DALEX','kernlab','pROC','nnet','RANN',
                      'ranger','GenomeInfoDb', 'GenomicRanges',
                      'GenomicAlignments', 'ComplexHeatmap', 'circlize', 
                      'rtracklayer', 'BSgenome.Hsapiens.UCSC.hg38',
                      'BSgenome.Hsapiens.UCSC.hg19','tidyr',
                      'AnnotationHub', 'GenomicFeatures', 'normr',
                      'MotifDb', 'TFBSTools', 'rGADEM', 'JASPAR2018'
                     ))
```

We also need the package that comes with the book. This contains data files needed for the analyses in the book. Files in the package are accessed using the system.file() function.

```{r  eval=FALSE, include=FALSE}

#First need to install devtools package

install.packages("devtools")

```

Now load the devtools package

```{r  eval=FALSE, include=FALSE}
library(devtools)
```

Now try installing the compgenomRpackage

```{r  eval=FALSE, include=FALSE}

devtools::install_github("compgenomr/compGenomRData")
```

Seems to have worked so far

Let's try reading in some files from the package.

```{r}

enhancerFilePath=system.file("extdata",
                "subset.enhancers.hg18.bed",
                package="compGenomRData")
cpgiFilePath=system.file("extdata",
                "subset.cpgi.hg18.bed",
                package="compGenomRData")
# read enhancer marker BED file
enh.df <- read.table(enhancerFilePath, header = FALSE) 

# read CpG island BED file
cpgi.df <- read.table(cpgiFilePath, header = FALSE) 

# check first lines to see how the data looks like
head(enh.df)

```

Nice!

Other ways to read in files is shown in the code below. The code is commented out so that is doesn't run.

```{r}
#library(data.table)
#df.f=d(enhancerFilePath, header = FALSE,data.table=FALSE)

#library(readr)
#df.f2=read_table(enhancerFilePath, col_names = FALSE)

```

Chapters 2 and 3 go over some basic R functionality. I'm skipping that here and jumping to chapter 4 because that starts analyzing the genomic data. I will return to chs 2 and 3 in a separate document.

## **Chapter 4** Exploratory Data Analysis with Unsupervised Machine Learning

### 4.1 Clustering

They use a simple table for the following illustration. I reproduced that as simple_patient_data and uploaded that file. Now let's read that into R as a dataframe called pd for patient data.

```{r}
# Installing
install.packages("readr")
# Loading
library("readr")
```

```{r}

#load the readxl library and import the dtaset



pd <- read.csv("simple_patient_data.csv", header =TRUE, row.names	= 1)




#View(pd)



```

Now let's see how we can calculate distances between the patients in R. We will use three distance methods.

-   the **"Manhattan distance"** or **"L1 norm"**.

-   **"Euclidean Distance"** or **"L2 norm"**

-   the **"correlation distance"**

```{r}
#first the manhattan method of the dist function.

dist(pd,method="manhattan")
```

Now try the Euclidean method

```{r}
dist(pd,method="euclidean")
```

Now the third method. correlation

```{r}
as.dist(1-cor(t(pd))) # correlation distance
```

#### An Aside on file importing.

Often I hear that one of the hardest parts about working in R is that it's difficult to import data. I think overall it's not as bad as they say, but I did just have a heck of a time getting a simple table imported into the format I wanted.

I simply made a table representing an example table from the text. I made the table in excel and saved both a .xlsx file and a .csv file. My first several attempts at reading in either of these files resulted in a variety of erros. The problem was basically that R wasn't recognizing the first column as row names. Turns out there are a lot of functions for reading tables. And they come in different packages.

Here's a few

read.table()

data.table()

read.csv

not to be confused with

read_csv

there's also:

read_excel

read.delimit

the list goes on.

What I found worked was to save the excel file as a csv file, then use the code shown in the code chunk above. It looks like this

pd \<- read.csv("simple_patient_data.csv", header =TRUE, row.names= 1)

So, it uses read.csv an older (I think) method. The arguments are the file name, header = TRUE so it knows the first row is the header for the the data. And row.names = 1, indicating that the first column (the patient IDs in this case) should be used as row names.

Once I did that, the table was read properly by the various distance functions.

Note - I also stumbled acrosse the idea that reader functions (part of the tidyverse) don't recognize row names. This must be part of the "tidy" organization of the data.

#### Normalizing the data

It is often necessary to normalize or standardize the data (see text for explanation). According to the text, a common way to normalize data is to subtract the mean and divide by the standard deviation for each value in the table. This is called "standardization". If this is done on all genes, each gene will have the same effect on distance.

The function to do this in R is called scale.

```{r}
scale(pd)
```

I suppose you would then go on to calcuate ditance on these scaled values.

First let's make a new data frame pd_scaled with the scaled data

```{r}
pd_scaled <- scale(pd)

```

```{r}

#first the manhattan method of the dist function.  

dist(pd_scaled,method="manhattan")
```

Now try the Euclidean method

```{r}

dist(pd_scaled,method="euclidean")
```

Now the third method. correlation

```{r}

as.dist(1-cor(t(pd_scaled))) # correlation distance
```

Maybe later I can add plotting and a comparison of these numbers. For now we'll leave that as an exercise for the reader :)

### **4.1.2** Hiearchical clustering

HC is one of the most ubiquitous clustering algorithms. Using this algorithm you can see the relationship of individual data points and relationships of clusters. Eventually, you get a tree structure or a dendrogram that shows the relationship between the individual data points and clusters. The height of the dendrogram is the distance between clusters. The base function in R to do hierarchical clustering in `hclust()`. Below, we apply that function on Euclidean distances between patients. The resulting clustering tree or dendrogram is shown in Figure [4.1](https://compgenomr.github.io/book/clustering-grouping-samples-based-on-their-similarity.html#fig:expPlot).

```{r}

d=dist(pd)
hc=hclust(d,method="complete")
plot(hc)
```

Cool. Patients 3 and 4 cluster together and 1 and 2 form another cluster.

Looking at the data supports this clustering. The values are as follows

p1 11 10 1

p2 13 13 3

p3 2 4 10

p4 1 3 9

patients 1 and 2 are low low high

patients 3 are high high low.

So the clustering makes sense.

See the text for a more thorough explanation of the hclust() function and its arguments.

#### Applying clustering to a larger data set and constructing a heat map.

A typical gene expression analysis comprises a much larger data set of course. One such data set contains gene expression values from 60 bone marrow samples of patients with one of the four main types of leukemia (ALL, AML, CLL, CML) or no-leukemia controls. The authors trimmed that data set down to the top 1000 most variable genes to be able to work with it more easily, since genes that are not very variable do not contribute much to the distances between patients. We will now use this data set to cluster the patients and display the values as a heatmap and a dendrogram. The heatmap function, pheatmap(), performs the clustering as well. The matrix that contains gene expressions has the genes in the rows and the patients in the columns. Therefore, we will also use a column-side color code to mark the patients based on their leukemia type. For the hierarchical clustering, we will use Ward's method designated by the clustering_method argument to the pheatmap() function.

```{r}
#load the heatmap library
library(pheatmap)

expFile=system.file("extdata","leukemiaExpressionSubset.rds",
                    package="compGenomRData")
mat=readRDS(expFile)                                      

# set the leukemia type annotation for each sample

annotation_col <- data.frame(LeukemiaType =substr(colnames(mat),1,3))

#add rownames corresponding to full sample names.  Results in a data frame with full genes as row names and one column Leukemia type with the abbreviated types.

rownames(annotation_col)=colnames(mat)
  
#next make a heatmap

pheatmap(mat,show_rownames=FALSE,show_colnames=FALSE,  #provide the data
         annotation_col=annotation_col,               #this is for the legend
         scale = "none",clustering_method="ward.D2",
         clustering_distance_cols="euclidean")


```

WHat is the following code doing?

data.frame(LeukemiaType =substr(colnames(mat),1,3)) rownames(annotation_col)=colnames(mat)

I believe we're making a data frame called LekemiaType, using the first three letters of the column names of the matrix we called mat. Each column name starts with a three letter designation of the leukemia type using the substring function. In english, this does the following

substr(colnames(mat), 1,3) extracts the column names from mat, then takes a substring of letters1:3 for each. This is saved in a variable called annotation_col

the next line

rownames(annotation_col)=colnames(mat)

Changes the rownames of the annotation_col to the full column names of mat. So we get a dat frame with fullnames as rownames and abbreviations as column 1. With the column name Leukemia type.

Then in the pheatmap function, there is a parameter in this function called annotation_col. Which means, tell me what you want to use for annotation (the legend essentially). In this case we made a dataframe called annotation_col, and so we use this as the legend.
