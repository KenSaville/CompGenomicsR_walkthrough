---
title: "CompGenR"
format: html
editor: visual
---

## Quarto

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>.

## Running Code

When you click the **Render** button a document will be generated that includes both content and the output of embedded code. You can embed code like this:

```{r}
1 + 1
```

You can add options to executable code like this

```{r}
#| echo: false
2 * 2
```

The `echo: false` option disables the printing of code (only output is displayed).

# Computational Genomics with R

This is my walkthrough of the book computational genomics with R by Altuna Alkalin, which can be found [here](https://compgenomr.github.io/book/).

### Compute resources

I'm starting out with the initial allocation from Posit.

1GB Ram, 1 CPU

We'll see if I need to / can bump that up if needed.

### Installations

First install all of the packages. Code copied from the preface of the book. Let's hope it works. That's a lot of packages.

```{r eval=FALSE, include=FALSE}

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install(c('qvalue','plot3D','ggplot2','pheatmap','cowplot',
                      'cluster', 'NbClust', 'fastICA', 'NMF','matrixStats',
                      'Rtsne', 'mosaic', 'knitr', 'genomation',
                      'ggbio', 'Gviz', 'DESeq2', 'RUVSeq',
                      'gProfileR', 'ggfortify', 'corrplot',
                      'gage', 'EDASeq', 'citr', 'formatR',
                      'svglite', 'Rqc', 'ShortRead', 'QuasR',
                      'methylKit','FactoMineR', 'iClusterPlus',
                      'enrichR','caret','xgboost','glmnet',
                      'DALEX','kernlab','pROC','nnet','RANN',
                      'ranger','GenomeInfoDb', 'GenomicRanges',
                      'GenomicAlignments', 'ComplexHeatmap', 'circlize', 
                      'rtracklayer', 'BSgenome.Hsapiens.UCSC.hg38',
                      'BSgenome.Hsapiens.UCSC.hg19','tidyr',
                      'AnnotationHub', 'GenomicFeatures', 'normr',
                      'MotifDb', 'TFBSTools', 'rGADEM', 'JASPAR2018'
                     ))
```

Also install the tidyverse

```{r}

install.packages("tidyverse")
```

```{r}

library(tidyverse)

```

We also need the package that comes with the book. This contains data files needed for the analyses in the book. Files in the package are accessed using the system.file() function.

```{r  eval=FALSE, include=FALSE}

#First need to install devtools package

install.packages("devtools")

```

Now load the devtools package

```{r  eval=FALSE, include=FALSE}
library(devtools)
```

Now try installing the compgenomRpackage

```{r  eval=FALSE, include=FALSE}

devtools::install_github("compgenomr/compGenomRData")
```

Seems to have worked so far

Let's try reading in some files from the package.

```{r}

enhancerFilePath=system.file("extdata",
                "subset.enhancers.hg18.bed",
                package="compGenomRData")
cpgiFilePath=system.file("extdata",
                "subset.cpgi.hg18.bed",
                package="compGenomRData")
# read enhancer marker BED file
enh.df <- read.table(enhancerFilePath, header = FALSE) 

# read CpG island BED file
cpgi.df <- read.table(cpgiFilePath, header = FALSE) 

# check first lines to see how the data looks like
head(enh.df)

```

Nice!

Other ways to read in files is shown in the code below. The code is commented out so that is doesn't run.

```{r}
#library(data.table)
#df.f=d(enhancerFilePath, header = FALSE,data.table=FALSE)

#library(readr)
#df.f2=read_table(enhancerFilePath, col_names = FALSE)

```

Chapters 2 and 3 go over some basic R functionality. I'm skipping that here and jumping to chapter 4 because that starts analyzing the genomic data. I will return to chs 2 and 3 in a separate document.

## **Chapter 4** Exploratory Data Analysis with Unsupervised Machine Learning

### 4.1 Clustering

They use a simple table for the following illustration. I reproduced that as simple_patient_data and uploaded that file. Now let's read that into R as a dataframe called pd for patient data.

```{r}
# Installing
install.packages("readr")
# Loading
library("readr")
```

```{r}

#load the readxl library and import the dtaset



pd <- read.csv("simple_patient_data.csv", header =TRUE, row.names	= 1)




#View(pd)



```

Now let's see how we can calculate distances between the patients in R. We will use three distance methods.

-   the **"Manhattan distance"** or **"L1 norm"**.

-   **"Euclidean Distance"** or **"L2 norm"**

-   the **"correlation distance"**

```{r}
#first the manhattan method of the dist function.

dist(pd,method="manhattan")
```

Now try the Euclidean method

```{r}
dist(pd,method="euclidean")
```

Now the third method. correlation

```{r}
as.dist(1-cor(t(pd))) # correlation distance
```

#### An Aside on file importing.

Often I hear that one of the hardest parts about working in R is that it's difficult to import data. I think overall it's not as bad as they say, but I did just have a heck of a time getting a simple table imported into the format I wanted.

I simply made a table representing an example table from the text. I made the table in excel and saved both a .xlsx file and a .csv file. My first several attempts at reading in either of these files resulted in a variety of erros. The problem was basically that R wasn't recognizing the first column as row names. Turns out there are a lot of functions for reading tables. And they come in different packages.

Here's a few

read.table()

data.table()

read.csv

not to be confused with

read_csv

there's also:

read_excel

read.delimit

the list goes on.

What I found worked was to save the excel file as a csv file, then use the code shown in the code chunk above. It looks like this

pd \<- read.csv("simple_patient_data.csv", header =TRUE, row.names= 1)

So, it uses read.csv an older (I think) method. The arguments are the file name, header = TRUE so it knows the first row is the header for the the data. And row.names = 1, indicating that the first column (the patient IDs in this case) should be used as row names.

Once I did that, the table was read properly by the various distance functions.

Note - I also stumbled acrosse the idea that reader functions (part of the tidyverse) don't recognize row names. This must be part of the "tidy" organization of the data.

#### Normalizing the data

It is often necessary to normalize or standardize the data (see text for explanation). According to the text, a common way to normalize data is to subtract the mean and divide by the standard deviation for each value in the table. This is called "standardization". If this is done on all genes, each gene will have the same effect on distance.

The function to do this in R is called scale.

```{r}
scale(pd)
```

I suppose you would then go on to calcuate ditance on these scaled values.

First let's make a new data frame pd_scaled with the scaled data

```{r}
pd_scaled <- scale(pd)

```

```{r}

#first the manhattan method of the dist function.  

dist(pd_scaled,method="manhattan")
```

Now try the Euclidean method

```{r}

dist(pd_scaled,method="euclidean")
```

Now the third method. correlation

```{r}

as.dist(1-cor(t(pd_scaled))) # correlation distance
```

Maybe later I can add plotting and a comparison of these numbers. For now we'll leave that as an exercise for the reader :)

### **4.1.2** Hiearchical clustering

HC is one of the most ubiquitous clustering algorithms. Using this algorithm you can see the relationship of individual data points and relationships of clusters. Eventually, you get a tree structure or a dendrogram that shows the relationship between the individual data points and clusters. The height of the dendrogram is the distance between clusters. The base function in R to do hierarchical clustering in `hclust()`. Below, we apply that function on Euclidean distances between patients. The resulting clustering tree or dendrogram is shown in Figure [4.1](https://compgenomr.github.io/book/clustering-grouping-samples-based-on-their-similarity.html#fig:expPlot).

```{r}

d=dist(pd)
hc=hclust(d,method="complete")
plot(hc)
```

Cool. Patients 3 and 4 cluster together and 1 and 2 form another cluster.

Looking at the data supports this clustering. The values are as follows

p1 11 10 1

p2 13 13 3

p3 2 4 10

p4 1 3 9

patients 1 and 2 are low low high

patients 3 are high high low.

So the clustering makes sense.

See the text for a more thorough explanation of the hclust() function and its arguments.

#### Applying clustering to a larger data set and constructing a heat map.

A typical gene expression analysis comprises a much larger data set of course. One such data set contains gene expression values from 60 bone marrow samples of patients with one of the four main types of leukemia (ALL, AML, CLL, CML) or no-leukemia controls. The authors trimmed that data set down to the top 1000 most variable genes to be able to work with it more easily, since genes that are not very variable do not contribute much to the distances between patients. We will now use this data set to cluster the patients and display the values as a heatmap and a dendrogram. The heatmap function, pheatmap(), performs the clustering as well. The matrix that contains gene expressions has the genes in the rows and the patients in the columns. Therefore, we will also use a column-side color code to mark the patients based on their leukemia type. For the hierarchical clustering, we will use Ward's method designated by the clustering_method argument to the pheatmap() function.

```{r}
#load the heatmap library
library(pheatmap)

expFile=system.file("extdata","leukemiaExpressionSubset.rds",
                    package="compGenomRData")
mat=readRDS(expFile)                                      

# set the leukemia type annotation for each sample

annotation_col <- data.frame(LeukemiaType =substr(colnames(mat),1,3))

#add rownames corresponding to full sample names.  Results in a data frame with full genes as row names and one column Leukemia type with the abbreviated types.

rownames(annotation_col)=colnames(mat)
  
#next make a heatmap

pheatmap(mat,show_rownames=FALSE,show_colnames=FALSE,  #provide the data
         annotation_col=annotation_col,               #this is for the legend
         scale = "none",clustering_method="ward.D2",
         clustering_distance_cols="euclidean")


```

What is the above code doing?

data.frame(LeukemiaType =substr(colnames(mat),1,3)) rownames(annotation_col)=colnames(mat)

I believe we're making a data frame called LekemiaType, using the first three letters of the column names of the matrix we called mat. Each column name starts with a three letter designation of the leukemia type using the substring function. In english, this does the following

substr(colnames(mat), 1,3) extracts the column names from mat, then takes a substring of letters1:3 for each. This is saved in a variable called annotation_col

the next line

rownames(annotation_col)=colnames(mat)

Changes the rownames of the annotation_col to the full column names of mat. So we get a dat frame with fullnames as rownames and abbreviations as column 1. With the column name Leukemia type.

Then in the pheatmap function, there is a parameter in this function called annotation_col. Which means, tell me what you want to use for annotation (the legend essentially). In this case we made a dataframe called annotation_col, and so we use this as the legend.

### **4.1.3** K-means clustering

```{r}

set.seed(101)

# we have to transpose the matrix t()
# so that we calculate distances between patients

kclu=kmeans(t(mat),centers=5)  

# number of data points in each cluster
table(kclu$cluster)

```

so t(mat) tranposes the matrix - switching rows and columns. Then the kmeans function is run on this, using 5 centers.

Table is a function that makes a table of a data frame or in this case a column. Counting up each different thing in a column and presenting the values in a table. In this case each patient was assigned to a cluseter (1 through 5). Then the numbers of patients in each cluster were counted and put in a table.

Let's walk through this a bit. If you view t(mat) you can see that the data frame now has the 60 patients as rownames and 1000 genes as columns. The data in each column are the expression levels of each gene.

```{r eval=FALSE, include=FALSE}

View(t(mat))

```

Running the kmeans function on this dataframe sorts patients into 5 clusters (because we told it to use 5 centers). We need to use set seed to control the randomness of the kmeans function

```{r}
set.seed(101)
kclu=kmeans(t(mat),centers=5)  
```

let's see the table generated this time. This is a table of the cluster column of the kclu object created by kmeans.

```{r}
table(kclu$cluster) #Note - the numbers in the table add up to 60, for 60 patients.
```

Next, we create a new dataframe with a column called LeukemiaType, created again by using substr to extract the first 3 letters of the column names (patients) from the original mat dataframe. This column will look like this

```{r}
substr(colnames(mat),1,3)
```

The second column is called cluster and contains the cluster assigned for each patient. This column looks like this

```{r}
kclu$cluster

```

Combining these columns into a dataframe using the data.frame function looks like this

```{r}

type2kclu = data.frame(
                    LeukemiaType =substr(colnames(mat),1,3),
                    cluster=kclu$cluster)

type2kclu


```

Making a table of this new dataframe shows how many patients in each cluster and associates each cluster with a leukemia type.

```{r}
table(type2kclu)
```

### Visualizing kmeans cluster

I found another function for visualizing kmeans results called fviz_cluster(). It is part of the factoextra package

```{r}
install.packages("factoextra")
```

```{r}

library(factoextra)
```

```{r}

fviz_cluster(kclu, t(mat))

```

Note - the above function includes geom_point and geom_text by default. This results in a cluttered plot.

below I plotted just the geom_point part. It would be good to label the clusters with ALL, CML etc. I'll try to figure that out later.

for more on the fviz_cluster() function see this link

[fvis_cluster](https://www.rdocumentation.org/packages/factoextra/versions/1.0.7/topics/fviz_cluster)

```{r}

fviz_cluster(kclu, t(mat), geom="point")

```

#### k-medoids clustering algorithm

Another related and maybe more robust algorithm is called "k-medoids" clustering (Reynolds, Richards, Iglesia, et al. 2006). The procedure is almost identical to k-means clustering with a couple of differences. In this case, centroids chosen are real data points in our case patients, and the metric we are trying to optimize in each iteration is based on the Manhattan distance to the centroid. In k-means this was based on the sum of squared distances, so Euclidean distance. Below we show how to use the k-medoids clustering function pam() from the cluster package.

```{r}
kmclu=cluster::pam(t(mat),k=5) #  cluster using k-medoids

# make a data frame with Leukemia type and cluster id
type2kmclu = data.frame(
                    LeukemiaType =substr(colnames(mat),1,3),
                    cluster=kmclu$cluster)

table(type2kmclu)
```

To visualize this data we need to compress between patient distances to a 2-dimensional plot. There are many ways to do this, and we introduce these dimension-reduction methods including the one we will use later in this chapter. For now, we are going to use a method called "multi-dimensional scaling" and plot the patients in a 2D plot color coded by their cluster assignments shown in Figure 4.5. We will explain this method in more detail in the Multi-dimensional scaling section below.

Note - the plotting below uses baseR plotting.

```{r}
# Calculate distances
dists=dist(t(mat))

# calculate MDS
mds=cmdscale(dists)

# plot the patients in the 2D space
plot(mds,pch=19,col=rainbow(5)[kclu$cluster]) 

#pch refers to the style of the dots.  it stands for "plotting character".  to see the available characters type ?pch in the console.

# set the legend for cluster colors
legend("bottomright",
       legend=paste("clu",unique(kclu$cluster)),
       fill=rainbow(5)[unique(kclu$cluster)],
       border=NA,box.col=NA)

```

Let's see if fvis_cluster works in this case.

```{r}

fviz_cluster(kmclu, t(mat), geom = "point")
```

silhouette values are a measure of how well points are mapped to theri relative clusters. In R, we can calculate silhouette values using the cluster::silhouette() function. Below, we calculate the silhouette values for k-medoids clustering with the pam() function with k=5.

```{r}

library(cluster)
set.seed(101)
pamclu=cluster::pam(t(mat),k=5)
plot(silhouette(pamclu),main=NULL)
```

Now, let us calculate the average silhouette value for different k values and compare. We will use sapply() function to get average silhouette values across k values between 2 and 7. Within sapply() there is an anonymous function that that does the clustering and calculates average silhouette values for each k. We also plot the average silhouette values for different values.

```{r}

Ks=sapply(2:7, function(i) summary(silhouette(pam(t(mat),k=i)))$avg.width)
plot(2:7,Ks,xlab="k",ylab="av. silhouette",type="b",
     pch=19)
```

sapply, like other apply functions, applies a particular function to elements of a vector or an object. Here the vector is the numbers 2-7 (2:7)

the function is: summary(silhouette(pam(t(mat),k=i)))\$avg.width

let's break it down.

the actual clustering function is pam, the k-medoids function from above. Let's rerun that function with k = 5 as we did before, and run the silhouett function on that to get the various silhouette values for each point in each cluster.

```{r}

silhouette(pam(t(mat),k=5))

```

Let's run summary on that function to see what we get

```{r}
summary(silhouette(pam(t(mat),k=5)))
```

We can extract the avg.width with dollar sign notation.

```{r}
summary(silhouette(pam(t(mat),k=5)))$avg.width

```

now, using sapply we can run this function across k values from 2 to 7

```{r}
Ks=sapply(2:7, function(i) summary(silhouette(pam(t(mat),k=i)))$avg.width)
```

and we can look at the resulting Ks object. Which is simply the avg.width for each K value

```{r}
Ks
```

```{r}
#let's make a dataframe, actually, let's make it a tibble
K_dist <- tibble(k=2:7, avg.mean=Ks)

#now plot w ggplot

K_dist %>% ggplot(aes(x=k, y=avg.mean)) + 
  geom_point(col="red") 
```

According to the CompGenomR text:

In this case, it seems the best value for k is 4. The k-medoids function pam() will usually cluster CML and "no Leukemia" cases together when k=4, which are also related clusters according to the hierarchical clustering we did earlier.

Why?

I'm thinking it's because the avg.mean is the avg mean between clusters. We want that to be high as it maximizes the distance between the clusters.

Let's retry this all with k=4

```{r}
kmclu4=cluster::pam(t(mat),k=4)

fviz_cluster(kmclu4, t(mat), geom = "point")

```

### **4.2.1** Principal component analysis

Principal component analysis (PCA) is maybe the most popular technique to examine high-dimensional data. There are multiple interpretations of how PCA reduces dimensionality. We will first focus on geometrical interpretation, where this operation can be interpreted as rotating the original dimensions of the data. For this, we go back to our example gene expression data set. In this example, we will represent our patients with expression profiles of just two genes, CD33 (ENSG00000105383) and PYGL (ENSG00000100504). This way we can visualize them in a scatter plot.

```{r}
#first using base R
plot(mat[rownames(mat)=="ENSG00000100504",],
     mat[rownames(mat)=="ENSG00000105383",],pch=19,
     ylab="CD33 (ENSG00000105383)",
     xlab="PYGL (ENSG00000100504)")
```

```{r}
#and now ggplot



# I think I need to convert mat to long format first.  Using gather

#I think the tranposed matrix might work.  Then we can just use patient designation as the columns to use for the plot

#mat_tibl <- as_tibble(t(mat)) #This doesn't inlcude rownames

#this should retain rownames
mat_tibl <- as_tibble(t(mat), rownames = pkgconfig::get_config("tibble::rownames", NA))

View(mat_tibl)



```

### Calculating principle components

First using base R as described in the text

```{r}
par(mfrow=c(1,2)) # set up plot area.  1 row 2 columns.  ie 2 plots side by side

# create the subset of the data with two genes only
# notice that we transpose the matrix so samples are on the columns
sub.mat=t(mat[rownames(mat) %in% c("ENSG00000100504","ENSG00000105383"),])

# plotting our genes of interest as scatter plots.  NOte data is scaled before plotting
plot(scale(mat[rownames(mat)=="ENSG00000100504",]),
     scale(mat[rownames(mat)=="ENSG00000105383",]),
     pch=19,
     ylab="CD33 (ENSG00000105383)",
     xlab="PYGL (ENSG00000100504)",
     col=as.factor(annotation_col$LeukemiaType), 
     # above must create colors based on the annotation_col df created using the first 3       letters of each lekemia_type.  Not sure how this works.  I'm thinking it just           assigns colors to points based on their order in the matrix.  The annotation_col         must have the leuk. types in the same order as the samples.
     
     xlim=c(-2,2),ylim=c(-2,2))

# create the legend for the Leukemia types
legend("bottomright",
       legend=unique(annotation_col$LeukemiaType),
       fill =palette("default"),
       border=NA,box.col=NA)

#This next bit seems to involve some somewhat complicated base R plotting.

# calculate the PCA only for our genes and all the samples
pr=princomp(scale(sub.mat))


# plot the direction of eigenvectors
# pr$loadings returned by princomp has the eigenvectors
arrows(x0=0, y0=0, x1 = pr$loadings[1,1], 
         y1 = pr$loadings[2,1],col="pink",lwd=3)
arrows(x0=0, y0=0, x1 = pr$loadings[1,2], 
         y1 = pr$loadings[2,2],col="gray",lwd=3)


# plot the samples in the new coordinate system
plot(-pr$scores,pch=19,
     col=as.factor(annotation_col$LeukemiaType),
     ylim=c(-2,2),xlim=c(-4,4))

# plot the new coordinate basis vectors
arrows(x0=0, y0=0, x1 =-2, 
         y1 = 0,col="pink",lwd=3)
arrows(x0=0, y0=0, x1 = 0, 
         y1 = -1,col="gray",lwd=3)
```

```{r}
# create the subset of the data with two genes only
# notice that we transpose the matrix so samples are 
# on the columns
sub.mat=t(mat[rownames(mat) %in% c("ENSG00000100504","ENSG00000105383"),])

# Using tidyverse

#use mat_tible which is the matrix converted to tibble
mat_tibl %>% ggplot(aes(x=ENSG00000100504, y= ENSG00000105383)) +
  geom_point(col="red") +
  labs(x="PYGL (ENSG00000100504)", y="CD33 (ENSG00000105383)")+
  theme_bw()
#select the two gene columns
mat_tibl %>% select(c("ENSG00000100504","ENSG00000105383"))

#this gives just the numbers, not row names
```

```{r}
#use mat_tible which is the matrix converted to tibble
mat_tibl %>% ggplot(aes(x=ENSG00000100504, y= ENSG00000105383)) +
  geom_point(col="red") +
  labs(x="PYGL (ENSG00000100504)", y="CD33 (ENSG00000105383)")+
  theme_bw()
```
